ğŸ“‚ Application Manager

A desktop utility built with Python + Tkinter (ttkbootstrap) to scan folders, detect duplicate files using SHA-256 hashing, categorize files based on custom keyword rules, and generate structured reports.

Designed for simple, fast local file management.

âœ¨ Features

ğŸ” Recursive folder scanning

ğŸ” Duplicate detection using SHA-256 hashing

ğŸ—‚ï¸ Keyword-based file categorization

âœï¸ GUI-based rule editor

ğŸ§¹ Duplicate file removal

ğŸ“ Automatic report generation

ğŸ“œ Logging system

ğŸŒ™ Dark-themed UI

ğŸ› ï¸ Requirements

Python 3.8+

ttkbootstrap

Install dependency:

pip install ttkbootstrap

â–¶ï¸ Running the Application
python main.py


The GUI window will open.

âš™ï¸ How It Works
1ï¸âƒ£ Folder Scanning

When you select a folder and click Scan, the application:

Recursively walks through all files

Calculates SHA-256 hash for each file

Detects duplicate files by comparing hashes

If two files have identical hashes â†’ they are marked as duplicates.

2ï¸âƒ£ File Categorization

Each file name is checked against keyword rules stored in:

rules.json


Example:

{
  "Games": ["game", "steam", "play"],
  "Development": ["code", "editor", "vscode"],
  "Utilities": ["setup", "tool"],
  "Media": ["music", "video"]
}


If a filename contains a keyword:

It is placed in that category

If no match is found â†’ it goes to Uncategorized

Rules can be edited directly from the GUI.

3ï¸âƒ£ Report Generation

After every scan:

A detailed session report is saved in:

/reports/session_report_<timestamp>.txt


The report includes:

Total duplicate files

Duplicate file paths

Categorized file lists

4ï¸âƒ£ Logging

Application activity is logged in:

/logs/app_log.log


This includes scan completion and report creation events.

5ï¸âƒ£ Duplicate Cleaning

Click Clean Duplicates to remove detected duplicate files.

âš ï¸ Files are permanently deleted using os.remove().

ğŸ“ Project Structure
Application-Manager/
â”‚
â”œâ”€â”€ main.py
â”œâ”€â”€ rules.json
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ app_log.log
â”‚
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ session_report_<timestamp>.txt
â”‚
â””â”€â”€ README.md

ğŸ”§ Core Logic Overview
Duplicate Detection
hashlib.sha256()


Files are read in chunks and hashed.
Matching hashes = duplicate files.

Categorization

Simple keyword match:

if keyword in filename.lower():
